{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the `./dataset` folder containing the images. There is a subdirectory for each class. In this case there will be 17 folders one for each food label in the alphabet.\n",
    "\n",
    "The complete tree looks like this:\n",
    "\n",
    "```\n",
    ".└── dataset/\n",
    "    ├── train/\n",
    "    |    ├── ayam/\n",
    "    |    │   ├── ayam1.jpg\n",
    "    |    │   ├── ayam2.jpg\n",
    "    |    │   └── ...\n",
    "    |    ├── brokoli/\n",
    "    |        ├── brokoli1.jpg\n",
    "    |        ├── brokoli2.jpg\n",
    "    |        └── ...\n",
    "    |    ├── ...\n",
    "    |    ├── telur/\n",
    "    |    |    ├── telur1.jpg\n",
    "    |    |    ├── telur2.jpg\n",
    "    |    |    └── ...\n",
    "    |    ├── tomat/\n",
    "    |    |    ├── tomat1.jpg\n",
    "    |    |    ├── tomat2.jpg\n",
    "    |    |    └── ...\n",
    "    |    ├── ...\n",
    "    |    └── wortel/\n",
    "    |        ├── wortel1.jpg\n",
    "    |        ├── wortel2.jpg\n",
    "    |        └── ...\n",
    "    └── validation/\n",
    "    |    ├── ayam/\n",
    "    |    │   ├── ayam1.jpg\n",
    "    |    │   ├── ayam2.jpg\n",
    "    |    │   └── ...\n",
    "    |    ├── brokoli/\n",
    "    |        ├── brokoli1.jpg\n",
    "    |        ├── brokoli2.jpg\n",
    "    |        └── ...\n",
    "    |    ├── ...\n",
    "    |    ├── telur/\n",
    "    |    |    ├── telur1.jpg\n",
    "    |    |    ├── telur2.jpg\n",
    "    |    |    └── ...\n",
    "    |    ├── tomat/\n",
    "    |    |    ├── tomat1.jpg\n",
    "    |    |    ├── tomat2.jpg\n",
    "    |    |    └── ...\n",
    "    |    ├── ...\n",
    "    |    └── wortel/\n",
    "    |        ├── wortel1.jpg\n",
    "    |        ├── wortel2.jpg\n",
    "    |        └── ...\n",
    "    └── test/\n",
    "         ├── ayam/\n",
    "         │   ├── ayam1.jpg\n",
    "         │   ├── ayam2.jpg\n",
    "         │   └── ...\n",
    "         ├── brokoli/\n",
    "         ├    ├── brokoli1.jpg\n",
    "         ├    ├── brokoli2.jpg\n",
    "         ├    └── ...\n",
    "         ├── ...\n",
    "         ├── telur/\n",
    "         |    ├── telur1.jpg\n",
    "         |    ├── telur2.jpg\n",
    "         |    └── ...\n",
    "         ├── tomat/\n",
    "         |    ├── tomat1.jpg\n",
    "         |    ├── tomat2.jpg\n",
    "         |    └── ...\n",
    "         ├── ...\n",
    "         └── wortel/\n",
    "             ├── wortel1.jpg\n",
    "             ├── wortel2.jpg\n",
    "             └── ...\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'dataset/train/'\n",
    "VALIDATION_DIR = 'dataset/validation/'\n",
    "TEST_DIR = 'dataset/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Dataset\n",
    "The dataset is already downloaded in the lab environment. It's on the base directory `daging-ayam`, which in turn contains `horses` and `humans` subdirectories. By arranging the data this way, you do not need to explicitly label the images as horses or humans. The utility you will use later automatically labels images according to this directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_datasets(dataset):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "    return train_dataset, val_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
